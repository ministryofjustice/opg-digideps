version: 2.1

workflows:
  pull_request:
    jobs:
      - cross-browser-test:
          name: cross browser test
          filters: { branches: { ignore: [ main ] } }

      - lint:
          name: lint terraform
          filters: { branches: { ignore: [ main ] } }
          requires: [ cross browser test]

      - build:
          name: build pr
          filters: { branches: { ignore: [ main ] } }
          requires: [ cross browser test]

      - terraform-command:
          name: plan shared development
          requires: [ lint terraform ]
          filters: { branches: { ignore: [ main ] } }
          tf_apply: false
          tf_command: plan
          tf_tier: shared
          tf_workspace: development

      - terraform-command:
          name: plan pr environment
          requires: [ lint terraform ]
          filters: { branches: { ignore: [ main ] } }
          tf_apply: false
          tf_command: plan
          tf_tier: environment

      - terraform-command:
          name: apply environment
          requires: [
            build pr,
            plan shared development,
            plan pr environment
             ]
          filters: { branches: { ignore: [ main ] } }
          tf_command: apply

      - client-unit-test:
          name: client unit test
          requires: [ build pr ]
          filters: { branches: { ignore: [ main ] } }

      - api-unit-tests:
          name: api unit test
          requires: [ build pr ]
          filters: { branches: { ignore: [ main ] } }

#      - pa11y-ci:
#          name: accessibility test
#          requires: [ apply environment ]
#          filters: { branches: { ignore: [ main ] } }
      - approve:
          name: approval for further testing
          type: approval
          requires: [ api unit test, client unit test, apply environment ]
          filters: { branches: { ignore: [ master ] } }

      - run-task:
          name: reset environment for testing
          requires: [ approval for further testing ]
          filters: { branches: { ignore: [ main ] } }
          task_name: reset_database
          timeout: 180

      - run-task:
          name: integration test
          requires: [ reset environment for testing ]
          filters: { branches: { ignore: [ master ] } }
          task_name: integration_test
          timeout: 2500

      - run-task:
          name: backup environment
          requires: [ integration test ]
          filters: { branches: { ignore: [ main ] } }
          task_name: backup

      - run-task:
          name: restore environment
          requires: [ backup environment ]
          filters: { branches: { ignore: [ main ] } }
          task_name: restore

      - cleanup:
          name: approve destroy environment
          type: approval
          requires: [ restore environment ]
          filters: { branches: { ignore: [ main ] } }

      - terraform-command:
          name: destroy environment
          requires: [ approve destroy environment ]
          filters: { branches: { ignore: [ main ] } }
          tf_command: destroy

  integration:
    jobs:
      - build:
          name: build integration
          build_dev: true
          filters: { branches: { only: [ main ] } }

      - terraform-command:
          name: apply shared-development
          requires: [ build integration ]
          filters: { branches: { only: [ main ] } }
          tf_tier: shared
          tf_workspace: development
          tf_command: apply

      # Notice, no 'reset' or 'restore' over development so we can keep test data
      - terraform-command:
          name: apply development
          requires: [ apply shared-development ]
          tf_workspace: development
          filters: { branches: { only: [ main ] } }
          tf_command: apply

      - terraform-command:
          name: plan shared-preproduction
          requires: [ apply shared-development ]
          filters: { branches: { only: [ main ] } }
          tf_tier: shared
          tf_workspace: preproduction
          tf_command: plan

      - terraform-command:
          name: plan preproduction
          requires: [ apply shared-development ]
          filters: { branches: { only: [ main ] } }
          tf_workspace: preproduction
          tf_command: plan

      - terraform-command:
          name: apply shared-preproduction
          requires: [ plan shared-preproduction, plan preproduction ]
          filters: { branches: { only: [ main ] } }
          tf_tier: shared
          tf_workspace: preproduction
          tf_command: apply

      - terraform-command:
          name: apply integration
          requires: [ apply shared-preproduction ]
          filters: { branches: { only: [ main ] } }
          tf_workspace: integration
          tf_command: apply

      - run-task:
          name: reset integration
          requires: [ apply integration ]
          filters: { branches: { only: [ main ] } }
          task_name: reset_database
          tf_workspace: integration
          timeout: 250

      - run-task:
          name: integration test
          requires: [ reset integration ]
          filters: { branches: { only: [ main ] } }
          task_name: integration_test
          tf_workspace: integration
          timeout: 2500

      - client-unit-test:
          name: client unit test
          requires: [ apply integration ]
          filters: { branches: { only: [ main ] } }

      - api-unit-tests:
          name: api unit test
          requires: [ apply integration ]
          filters: { branches: { only: [ main ] } }

      - terraform-command:
          name: apply training
          requires: [ apply shared-production ]
          filters: { branches: { only: [ main ] } }
          tf_workspace: training
          tf_command: apply

      - terraform-command:
          name: apply preproduction
          requires: [ api unit test, client unit test, integration test ]
          filters: { branches: { only: [ main ] } }
          tf_workspace: preproduction
          tf_command: apply

      - terraform-command:
          name: plan production
          requires: [ apply preproduction ]
          filters: { branches: { only: [ main ] } }
          tf_workspace: production02
          tf_command: plan

      - terraform-command:
          name: plan shared-production
          requires: [ apply preproduction ]
          filters: { branches: { only: [ main ] } }
          tf_tier: shared
          tf_workspace: production
          tf_command: plan

      - slack/approval-notification:
          name: release approval notification
          message: "Production is ready for release and pending approval"
          requires: [ plan shared-production, plan production ]
          filters: { branches: { only: [ main ] } }

      - approve:
          name: approve release to production
          type: approval
          requires: [ plan shared-production, plan production ]
          filters: { branches: { only: [ main ] } }

      - terraform-command:
          name: apply shared-production
          requires: [ approve release to production ]
          filters: { branches: { only: [ main ] } }
          tf_tier: shared
          tf_workspace: production
          tf_command: apply

      - terraform-command:
          name: apply production
          requires: [ apply shared-production ]
          filters: { branches: { only: [ main ] } }
          pact_tag: true
          tf_workspace: production02
          tf_command: apply

      - run-task:
          name: backup production
          requires: [ apply production ]
          filters: { branches: { only: [ main ] } }
          task_name: backup
          tf_workspace: production02
          timeout: 700

      - run-task:
          name: restore production to preproduction
          requires: [ backup production ]
          filters: { branches: { only: [ main ] } }
          task_name: restore_from_production
          tf_workspace: preproduction
          timeout: 700

  weekly_integration_run:
    triggers:
      - schedule:
          cron: "00 05 * * 0"
          filters: { branches: { only: [ main ] } }
    jobs:
      - build:
          name: build integration
          filters: { branches: { only: [ main ] } }
      - terraform-command:
          name: apply integration
          requires: [ build integration ]
          filters: { branches: { only: [ main ] } }
          tf_workspace: integration
          tf_command: apply
      - run-task:
          name: reset integration
          requires: [ apply integration ]
          filters: { branches: { only: [ main ] } }
          task_name: reset_database
          tf_workspace: integration
          timeout: 250
      - client-unit-test:
          name: client unit test
          requires: [ apply integration ]
          filters: { branches: { only: [ main ] } }
      - api-unit-tests:
          name: api unit test
          requires: [ apply integration ]
          filters: { branches: { only: [ main ] } }
      - run-task:
          name: integration test
          requires: [ reset integration ]
          filters: { branches: { only: [ main ] } }
          task_name: integration_test
          tf_workspace: integration
          notify_slack: true
          timeout: 2500

orbs:
  aws-cli: circleci/aws-cli@0.1.13
  slack: circleci/slack@3.4.2
  codecov: codecov/codecov@1.1.1
  dockerhub_helper:
    orbs:
      docker: circleci/docker@1.4.0
    commands:
      dockerhub_login:
        steps:
          - docker/install-docker-credential-helper
          - docker/check:
              docker-password: DOCKER_ACCESS_TOKEN
              docker-username: DOCKER_USER
  ecs_helper:
    commands:
      install:
        steps:
          - run:
              name: Install runner
              working_directory: ~/project/ecs_helper
              command: go install -mod vendor ./cmd/runner
          - run:
              name: Install stabilizer
              working_directory: ~/project/ecs_helper
              command: go install -mod vendor ./cmd/stabilizer
          - run:
              name: Install pact_tags
              working_directory: ~/project/ecs_helper
              command: go install -mod vendor ./cmd/pact_tags
          - run:
              name: Build redeployer
              working_directory: ~/project/shared/go_redeployer
              command: GOARCH=amd64 GOOS=linux go build -o main ./main.go
  terraform:
    executors:
      terraform:
        docker:
          - image: circleci/golang:1.12
            auth:
              username: $DOCKER_USER
              password: $DOCKER_ACCESS_TOKEN
        resource_class: small
        environment:
          TF_VERSION: 0.13.5
          TF_SHA256SUM: f7b7a7b1bfbf5d78151cfe3d1d463140b5fd6a354e71a7de2b5644e652ca5147
          TF_CLI_ARGS_plan: -input=false -lock=false
          TF_CLI_ARGS_apply: -input=false -auto-approve
          TF_CLI_ARGS_destroy: -input=false -auto-approve
          TF_CLI_ARGS_init: -input=false -upgrade=true -reconfigure
    commands:
      install:
        steps:
          - run:
              name: Download Terraform
              command: curl -sfSO https://releases.hashicorp.com/terraform/${TF_VERSION}/terraform_${TF_VERSION}_linux_amd64.zip
          - run:
              name: Add Terraform SHA256SUM
              command: echo "${TF_SHA256SUM} terraform_${TF_VERSION}_linux_amd64.zip" > SHA256SUMS
          - run:
              name: Check Terraform SHA256SUM
              command: sha256sum -c --status SHA256SUMS
          - run:
              name: Install Terraform
              command: sudo unzip terraform_${TF_VERSION}_linux_amd64.zip -d /bin

jobs:
  lint:
    executor: terraform/terraform
    resource_class: small
    steps:
      - checkout
      - terraform/install
      - run:
          name: terraform lint
          command: terraform fmt -diff -check -recursive

  terraform-command:
    executor: terraform/terraform
    resource_class: small
    parameters:
      tf_workspace:
        description: terraform workspace
        type: string
        default: ""
      tf_tier:
        description: tier to alter - shared or environment
        default: environment
        type: string
      tf_command:
        description: terraform command
        type: string
      tf_apply:
        description: whether this is a terraform apply
        default: true
        type: boolean
      pact_tag:
        description: whether to add environment tag to pact broker
        default: false
        type: boolean
    environment:
      TF_TIER: << parameters.tf_tier >>
      WORKSPACE: << parameters.tf_workspace >>
    working_directory: ~/project/<< parameters.tf_tier >>
    steps:
      - checkout:
          path: ~/project
      - terraform/install
      - ecs_helper/install
      - attach_workspace: { at: ~/project }
      - when:
          condition: << parameters.tf_apply >>
          steps:
            - run:
                name: Extract lambda layers
                working_directory:  ~/project/lambda_functions
                command: tar xvf ~/project/lambda_functions/layer.tar
      - run:
          name: Initialize
          command: terraform init
      - run:
          name: Set environment
          command: ~/project/.circleci/set_env.sh >> $BASH_ENV
      - run:
          name: Run << parameters.tf_command >>
          command: terraform << parameters.tf_command >>
      - when:
          condition: << parameters.tf_apply >>
          steps:
            - run:
                name: Output
                command: terraform output -json > terraform.output.json
            - run:
                name: Stabilize
                command: stabilizer
      - when:
          condition: << parameters.pact_tag >>
          steps:
            - run:
                name: set pact environment variables
                command: ~/project/.circleci/set_env_pact.sh >> $BASH_ENV
            - run:
                name: tag pact commit with v<x>_production
                command: pact_tags

  build:
    docker:
      - image: circleci/python:3
        auth:
          username: $DOCKER_USER
          password: $DOCKER_ACCESS_TOKEN
    resource_class: small
    environment:
      AWS_REGION: eu-west-1
      AWS_CONFIG_FILE: ~/project/aws_config
      AWS_REGISTRY: 311462405659.dkr.ecr.eu-west-1.amazonaws.com
    parameters:
      build_dev:
        description: whether to build the development client image
        type: boolean
        default: false
    steps:
      - dockerhub_helper/dockerhub_login
      - setup_remote_docker
      - aws-cli/install
      - add_ssh_keys:
          fingerprints:
            - 6f:4b:55:76:0e:cd:27:7d:ad:c3:28:38:53:69:5c:32
      - checkout
      - run:
          name: Cancel running builds
          command: |
            python cancel_redundant_builds.py \
            --circle_project_username="${CIRCLE_PROJECT_USERNAME}" \
            --circle_project_reponame="${CIRCLE_PROJECT_REPONAME}" \
            --circle_branch="${CIRCLE_BRANCH}" \
            --circle_builds_token="${CIRCLE_BUILDS_TOKEN}" \
            --terms_to_waitfor="apply,plan" \
            --prod_job_terms=" production,shared-production"
          working_directory: ~/project/ecs_helper/cmd/circle_builds
      - run:
          name: Set environment
          command: ~/project/.circleci/set_env.sh >> $BASH_ENV
      - run:
          name: Set version
          command: |
            export VERSION=${TF_WORKSPACE}-${CIRCLE_SHA1:0:7}
            export DEV_VERSION=development-${CIRCLE_SHA1:0:7}
            echo "export VERSION=${VERSION}" >> $BASH_ENV
            echo "export DEV_VERSION=${DEV_VERSION}" >> $BASH_ENV
            echo "$VERSION" >> ~/project/VERSION
      - persist_to_workspace:
          root: .
          paths:
            - VERSION
      - run:
          name: Show version
          command: echo ${VERSION}
      - run:
          name: Docker login
          command: eval $(aws ecr get-login --region $AWS_REGION --no-include-email --profile digideps-ci)
      - run:
          name: Build images
          command: docker-compose -f docker-compose.ci.yml build --parallel
      - run:
          name: List API packages
          command: docker-compose -f docker-compose.ci.yml run --rm api apk list | sort
      - run:
          name: List client packages
          command: docker-compose -f docker-compose.ci.yml run --rm client apk list | sort
      - run:
          name: Check updated PHP files for errors
          command: |
            MERGE_BASE_COMMIT=( $(git merge-base main HEAD) )
            API_CHANGED_FILES=( $(git diff --relative=api --name-only --diff-filter=d $MERGE_BASE_COMMIT | grep .php) ) || [[ $? == 1 ]]
            CLIENT_CHANGED_FILES=( $(git diff --relative=client --name-only --diff-filter=d $MERGE_BASE_COMMIT | grep .php) ) || [[ $? == 1 ]]

            if [ -n "$API_CHANGED_FILES" ]; then
                docker-compose -f docker-compose.ci.yml run --rm api php bin/phpstan analyse $API_CHANGED_FILES --memory-limit=0 --level=max
            fi

            if [ -n "$CLIENT_CHANGED_FILES" ]; then
                docker-compose -f docker-compose.ci.yml run --rm client php bin/phpstan analyse $CLIENT_CHANGED_FILES --memory-limit=0 --level=max
            fi
      - run:
          name: Push images
          command: docker-compose -f docker-compose.ci.yml push
      - when:
          condition: << parameters.build_dev >>
          steps:
            - run:
                name: add robots.txt to frontend development
                command: docker-compose -f docker-compose.ci.dev.yml build --build-arg AWS_REGISTRY=${AWS_REGISTRY} --build-arg VERSION=${VERSION}
            - run:
                name: Push image
                command: docker-compose -f docker-compose.ci.dev.yml push
      - run:
          name: Install ECR Scan Results Requirements
          working_directory: ~/project/ecs_helper/check_ecr_scan_results
          command: |
            sudo pip3 install -r requirements.txt
      - run:
          name: Check ECR Scan Results
          working_directory: ~/project/ecs_helper/check_ecr_scan_results
          command: |
            python3 aws_ecr_scan_results.py --search digideps --tag $VERSION --post_to_slack True
      - run:
          name: Archive docker images
          command: |
            docker tag ${AWS_REGISTRY}/digideps/client:${VERSION} client:latest
            docker save -o docker-images.tar client:latest
      - run:
          name: install requirements for all lambda layers
          command: |
            export LAYER_PATH=lambda_functions/layers/monitoring/python/lib/python3.7/site-packages
            pip3 install -r lambda_functions/requirements/requirements.txt --target ./$LAYER_PATH/
            cd lambda_functions
            tar cvf layer.tar layers
      - persist_to_workspace:
          root: .
          paths:
            - ./docker-images.tar
            - ./lambda_functions/layer.tar

  client-unit-test:
    docker:
      - image: circleci/python:3
        auth:
          username: $DOCKER_USER
          password: $DOCKER_ACCESS_TOKEN
    resource_class: small
    steps:
      - dockerhub_helper/dockerhub_login
      - setup_remote_docker
      - checkout
      - attach_workspace: { at: ~/project }
      - run:
          name: Install lambda requirements for unit tests
          working_directory: ~/project/lambda_functions
          command: |
            docker-compose up -d
            sleep 5
            docker-compose run pythontests python -m pytest
            docker-compose down
          background: true
      - run:
          name: install aws cli
          command: |
            pip3 install awscli --upgrade --user
            aws --version
      - run:
          name: Set environment
          command: |
            ~/project/.circleci/set_env.sh >> $BASH_ENV
            ~/project/.circleci/set_env_pact.sh >> $BASH_ENV
      - run:
          name: Run tests
          command: |
            docker-compose -f docker-compose.yml --project-name client-unit-tests up -d --no-deps frontend pact-mock
            sleep 3

            docker-compose -f docker-compose.yml --project-name client-unit-tests exec frontend sh scripts/client-unit-tests.sh
            docker-compose -f docker-compose.yml --project-name client-unit-tests exec frontend chmod -R 777 tests/phpunit/coverage/client-unit-tests.xml
            docker cp "client-unit-tests_frontend_1:/var/www/tests/phpunit/coverage/client-unit-tests.xml" "./client-unit-tests.xml"

            docker-compose -f docker-compose.yml --project-name client-unit-tests exec pact-mock cat /tmp/pacts/complete_the_deputy_report-opg_data.json > pact.json
            docker-compose -f docker-compose.yml --project-name client-unit-tests stop pact-mock
      - codecov/upload:
          file: ./client-unit-tests.xml
          flags: client
      - store_artifacts:
          path: pact.json
          destination: Pact file

  api-unit-tests:
    docker:
      - image: circleci/php
        auth:
          username: $DOCKER_USER
          password: $DOCKER_ACCESS_TOKEN
    resource_class: small
    steps:
      - dockerhub_helper/dockerhub_login
      - setup_remote_docker
      - checkout
      - attach_workspace: { at: ~/project }
      - run:
          name: Set environment
          command: |
            ~/project/.circleci/set_env.sh >> $BASH_ENV
      - run:
          name: Run tests
          command: |
            docker-compose -f docker-compose.yml --project-name api-unit-tests up -d api
            docker-compose -f docker-compose.yml --project-name api-unit-tests exec api chmod -R 777 var
            docker-compose -f docker-compose.yml --project-name api-unit-tests up -d localstack
            docker-compose -f docker-compose.yml --project-name api-unit-tests run --rm wait-for-it -address localstack:4583 --timeout=20 -debug
            docker-compose -f docker-compose.yml --project-name api-unit-tests run --rm wait-for-it -address localstack:4586 --timeout=20 -debug
            docker-compose -f docker-compose.yml --project-name api-unit-tests up -d localstack-init
            docker-compose -f docker-compose.yml --project-name api-unit-tests exec api sh scripts/apiunittest.sh

            docker-compose -f docker-compose.yml --project-name api-unit-tests exec api chmod -R 777 tests/coverage/api-unit-tests.xml
            docker cp "api-unit-tests_api_1:/var/www/tests/coverage/api-unit-tests.xml" "./api-unit-tests.xml"
      - codecov/upload:
          file: ./api-unit-tests.xml
          flags: api

  cross-browser-test:
    docker:
      - image: circleci/python:3
        auth:
          username: $DOCKER_USER
          password: $DOCKER_ACCESS_TOKEN
    resource_class: small
    steps:
      - dockerhub_helper/dockerhub_login
      - setup_remote_docker
      - aws-cli/install
      - checkout
      - attach_workspace: { at: ~/project }
      - run:
          name: Set environment
          command: |
            ~/project/.circleci/set_env.sh >> $BASH_ENV
      - run:
          name: Get secrets
          command: |
            chmod 755 ecs_helper/cmd/get_secrets/get_secrets.sh
            ./ecs_helper/cmd/get_secrets/get_secrets.sh
            echo "BROWSERSTACK_USERNAME=$BROWSERSTACK_USERNAME" >> behat/.env
            echo "BROWSERSTACK_KEY=$BROWSERSTACK_KEY" >> behat/.env
            echo "export BROWSERSTACK_KEY=$BROWSERSTACK_KEY" >> $BASH_ENV
      - run:
          name: Run tests
          command: |
            docker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d --build --remove-orphans
            docker-compose -f docker-compose.yml -f docker-compose.dev.yml run --rm api sh scripts/reset_db_structure_local.sh
            docker-compose -f docker-compose.yml -f docker-compose.dev.yml run --rm api sh scripts/reset_db_fixtures_local.sh

            ./BrowserStackLocal --daemon "start" --key $BROWSERSTACK_KEY

            docker-compose -f docker-compose.yml -f docker-compose.dev.yml run test --profile cross-browser-chrome --suite chrome
            docker-compose -f docker-compose.yml -f docker-compose.dev.yml run test --profile cross-browser-ie11 --suite ie11
            docker-compose -f docker-compose.yml -f docker-compose.dev.yml run test --profile cross-browser-android --suite android

            ./BrowserStackLocal --daemon "stop" --key $BROWSERSTACK_KEY

  pa11y-ci:
    machine:
      image: circleci/classic:latest
    steps:
      - dockerhub_helper/dockerhub_login
      - checkout
      - attach_workspace: { at: ~/project }
      - run:
          name: Set environment
          command: |
            ~/project/.circleci/set_env.sh >> $BASH_ENV
      - run:
          name: Run pa11y
          command: |
            docker-compose down
            docker-compose -f docker-compose.yml up -d pa11y
            docker-compose exec frontend touch /var/www/.enableProdMode
            docker-compose exec admin touch /var/www/.enableProdMode
            docker-compose exec api touch /var/www/.enableProdMode
            docker-compose -f docker-compose.yml run --rm api sh scripts/reset_db_structure.sh
            docker-compose -f docker-compose.yml run --rm api sh scripts/reset_db_fixtures.sh
            sleep 10
            docker-compose -f docker-compose.yml run pa11y pa11y-ci || echo "Pa11y found some errors"

            # The || operator ensures that if pa11y exits with an error code, we echo an informative message
            # instead of failing the job and the pipeline too.

  run-task:
    executor: terraform/terraform
    resource_class: small
    parameters:
      tf_workspace:
        description: terraform workspace
        type: string
        default: ""
      task_name:
        description: name of task to run
        type: string
      timeout:
        description: time the task will run for before timing out
        type: integer
        default: 120
      notify_slack:
        description: whether to notify specific task failure
        type: boolean
        default: false
    environment:
      WORKSPACE: << parameters.tf_workspace >>
    working_directory: ~/project/environment
    steps:
      - checkout:
          path: ~/project
      - terraform/install
      - ecs_helper/install
      - run:
          name: Initialize
          command: terraform init
      - run:
          name: Set environment
          command: ~/project/.circleci/set_env.sh >> $BASH_ENV
      - run:
          name: Output
          command: terraform output -json > terraform.output.json
      - run:
          name: Run task
          command: runner -task << parameters.task_name >> -timeout << parameters.timeout >>
      - when:
          condition: << parameters.notify_slack >>
          steps:
            - slack/status:
                channel: opg-digideps-team
                failure_message: << parameters.task_name >> has failed.
                success_message: << parameters.task_name >> has succeeded.
